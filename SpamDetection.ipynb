{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256fade4",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e98efe",
   "metadata": {},
   "source": [
    "### Problem Area\n",
    "\n",
    "The challenge with spam detection technologies is effectively distinguishing between spam and legitimate messages in a variety of settings, including social media, messaging platforms, and email to improve user experience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6b7f0a",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "The main objectives of spam detection are to safeguard you from unsolicited communications, conserve your time and effort, and guarantee that you only get communication that is pertinent and crucial. It serves as a filter, keeping your inbox clear and preventing frauds and time-wasting dealing with unimportant communications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55cb11e",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "‘SMS Spam Collection Dataset’ dataset available from the Kaggle website. The files contain one message per line. Each line has two columns: v1 has the label (ham or spam) and v2 has the raw text. This dataset was gathered from various sources on the internet, either freely available or free for research purposes. \n",
    "\n",
    "A collection of 425 SMS spam messages was manually extracted from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received.\n",
    "\n",
    "A subset of 3,375 SMS randomly chosen ham messages of the NUS SMS Corpus (NSC), which is a dataset of about 10,000 legitimate messages collected for research at the Department of Computer Science at the National University of Singapore. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available.\n",
    "\n",
    "A list of 450 SMS ham messages collected from Caroline Tag's PhD Thesis.\n",
    "\n",
    "Finally, we have incorporated the SMS Spam Corpus v.0.1 Big. It has 1,002 SMS ham messages and 322 spam messages and it is public available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e14d2",
   "metadata": {},
   "source": [
    "### Evaluation Methodology\n",
    "The evaluation metrics I will be using are precision and accuracy. When the goal is to reduce false positives and make sure that a model's positive predictions are very accurate, precision score is very important. And accuracy is being used as it is an easy to interpret evaluation metric ans dit provides a single number to evaluate the model's capability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7edb04",
   "metadata": {},
   "source": [
    "#### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2a1eab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: scikit-learn in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: regex in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (2022.7.9)\n",
      "Requirement already satisfied: numpy in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (1.21.5)\n",
      "Requirement already satisfied: pandas in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (1.4.4)\n",
      "Requirement already satisfied: wordcloud in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (1.9.2)\n",
      "Requirement already satisfied: matplotlib in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (3.5.2)\n",
      "Requirement already satisfied: click in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: pillow in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gourisrinijag/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install nltk scikit-learn regex numpy pandas wordcloud matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9aed2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7962617",
   "metadata": {},
   "source": [
    "#### Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "090a11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('spam.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "668f5acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ca8bfbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5eb16e",
   "metadata": {},
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a2b9ee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3cbcde9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unecessary columns\n",
    "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8cf1bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns\n",
    "df.rename(columns = {'v1':'target', 'v2': 'text'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "53b5c312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "040673c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cheking duplicated values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c8679470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removing duplicates; (5572, 2)\n",
      "after removing duplicates (5169, 2)\n"
     ]
    }
   ],
   "source": [
    "#dropping duplicates value\n",
    "print(\"before removing duplicates;\",df.shape)\n",
    "df.drop_duplicates(keep='first',inplace=True)\n",
    "print(\"after removing duplicates\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "499edf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f1d1d3",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13e6fe4",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd45ec1",
   "metadata": {},
   "source": [
    "#### Removing Stopwords, punctuation and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7151cc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gourisrinijag/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "#Function to transform the text\n",
    "def transform_text(text):\n",
    "    \n",
    "    #Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Tokenize the text into individual words\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    #Create and empty list to store filtered words\n",
    "    filtered_words = []\n",
    "    \n",
    "    for word in text:\n",
    "        if word.isalnum():\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    #update the text\n",
    "    text = filtered_words[:]\n",
    "    \n",
    "    #Clear the filtered words list for reuse\n",
    "    filtered_words.clear()\n",
    "    \n",
    "    #Remove stopwords and punctuation from the text\n",
    "    for word in text:\n",
    "        if word not in stopwords.words('english') and word not in string.punctuation:\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    #update the text\n",
    "    text = filtered_words[:]\n",
    "    \n",
    "    #Clear the filtered words list for reuse\n",
    "    filtered_words.clear()\n",
    "    \n",
    "     # Apply stemming to the words in the text\n",
    "    stemmer = PorterStemmer()\n",
    "    for word in text:\n",
    "        # Perform stemming on each word\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        # Add the stemmed word to the filtered list\n",
    "        filtered_words.append(stemmed_word)\n",
    "    \n",
    "    #join the filtered words to form the transformed text\n",
    "    transformed_text = \" \".join(filtered_words)\n",
    "    \n",
    "    #return the transformed text\n",
    "    return transformed_text\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "af2fda63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a new column\n",
    "df['transformed_text'] = df['text'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "674df142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4               nah think goe usf live around though  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689e0bf",
   "metadata": {},
   "source": [
    "#### Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fe4a31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "766b1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(df['transformed_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d196b93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 6708)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ff9076e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "237247a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b63e0e",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5955a351",
   "metadata": {},
   "source": [
    "#### Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "54cad458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9f5b243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "# Create a Multinomial Naive Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "# Create a Bernoulli Naive Bayes classifier\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87265d6d",
   "metadata": {},
   "source": [
    "##### Gaussian Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3cf04b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8800773694390716\n",
      "[[792 104]\n",
      " [ 20 118]]\n",
      "0.5315315315315315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred1 = gnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred1))\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(precision_score(y_test,y_pred1, pos_label='spam'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7215f5",
   "metadata": {},
   "source": [
    "##### Multinominal Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3426708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9700193423597679\n",
      "[[893   3]\n",
      " [ 28 110]]\n",
      "0.9734513274336283\n"
     ]
    }
   ],
   "source": [
    "bnb.fit(X_train,y_train)\n",
    "y_pred3 = bnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred3))\n",
    "print(confusion_matrix(y_test,y_pred3))\n",
    "print(precision_score(y_test,y_pred3, pos_label='spam'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9eb818",
   "metadata": {},
   "source": [
    "##### Bernoulli Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cf886839",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9642166344294004\n",
      "[[871  25]\n",
      " [ 12 126]]\n",
      "0.8344370860927153\n"
     ]
    }
   ],
   "source": [
    "mnb.fit(X_train,y_train)\n",
    "y_pred2 = mnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(confusion_matrix(y_test,y_pred2))\n",
    "print(precision_score(y_test, y_pred2, pos_label='spam'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b111e1",
   "metadata": {},
   "source": [
    "### Classification approach\n",
    "\n",
    "A Support Vector Machine (SVM) classifier with a linear kernel is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ca8a5309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "986ee6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = svm.SVC(kernel='linear')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ecfb4887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777562862669246\n",
      "Precison: 0.9752066115702479\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       896\n",
      "        spam       0.98      0.86      0.91       138\n",
      "\n",
      "    accuracy                           0.98      1034\n",
      "   macro avg       0.98      0.93      0.95      1034\n",
      "weighted avg       0.98      0.98      0.98      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "precison = precision_score(y_test, y_pred,pos_label='spam')\n",
    "print(\"Precison:\", precison)\n",
    "\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05f233",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12eb7fe",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "I have used the Naive Bayes algorihtm as my baseline. I used 3 classifier models namely the Multinomial Naive Bayes classifier, Gaussian Naive Bayes classifier and the Bernoulli Naive Bayes classifier. The Multinomial Navie Bayes has a accuracy score of 0.97 and a precision score of 0.97. Since my SVM classifier has a similar accuracy and precision score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b73769",
   "metadata": {},
   "source": [
    "### Citations\n",
    "\n",
    "“The National University of Singapore SMS Corpus | ScholarBank@NUS.” The National University of Singapore SMS Corpus | ScholarBank@NUS, doi.org/10.25540/WVM0-4RNX.\n",
    "\n",
    "Tagg, Caroline. “A corpus linguistics study of SMS text messaging.” (2009)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
